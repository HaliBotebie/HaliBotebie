{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> HomePage <p></p> Yixiong Yan (\u4e25\u4e49\u96c4) Algorithm Engineer at Perception and Fusion Team Department of Intelligent Driving Software Development Dongfeng Motor Corporation Research&amp;Development Institute, Wuhan, China, 430056 Master. Student at Wuhan University, Wuhan, China Bachelor. Student at South China University of Technology, Guangzhou, China Email: meeason@foxmail.com <p></p> <p> </p> Biography <p>Yixiong Yan is a Perception Algorithm Engineer in Department of Intelligent Driving Software Development,  Dongfeng Motor Corporation Research&amp;Development Institute (formerly known as the \u201cDongfeng Motor Group Co., Ltd. Technology Center\u201d) starting from Autumn 2019, Wuhan, China. His research and development advisor is Hang Yang(2020-2021), Xinjuan Tuo(2022-2024).</p> <p>Yixiong Yan received the B. E. degree from School of Mechanical and Automotive Engineering,  South China University of Technology, Guangzhou, China, in 2019. He will receive the M. A. degree from School of Politics and Public Administration, Wuhan University, Wuhan, China, in 2025.</p> <p>Yixiong Yan\u2019s research interests include visual perception and visual location  in the field of autonomous driving, with a focus on generic/oriented/3D object detection, lane detection and SLAM. He has published some papers at the international conferences and journals and published some key patents. He is the leading contributor to the BEV perception(2022-2024) and IPM SLAM(2020-2021) scientific research projects, and lane detection module application (2020-2021)  in mass-produced vehicles based on Mobileye in Dongfeng Motor Group Co., Ltd..</p> <p>The autonomous driving software department at Dongfeng Motor Corporation Research&amp;Development Institute is now hiring. If you are interested in internship/researcher positions related to autonomous driving perception in the filed of lidar or camera, please feel free to contact me through the email. </p> <p> </p> \ud83d\udd25My Recent Works <ul> <li> 11/2023: Research on the BANGC programming model and CNNL neural network library for Heterogeneous Hybrid Parallel Computing based on the Cambrian AI chip SD5223C. Explore the possibility of using it in the next step of scientific research plans, Wuhan.</li> <li> 11/2023: Closed-door meeting on autonomous driving simulation and digital twin test and evaluation tool chain projects. The meeting analyzed the latest progress in vehicle complex dynamics (white box, gray box, black box) modeling, guidance on critical scenarios of traffic interference based on UN ECE R157 regulatory annex and human driver baseline, scene generation framework, etc. Professor Zhu Xichan of Tongji University is very helpful\ud83d\udc4d! Wuxi, Zhejiang, November 10th.</li> <li> 07/2023: L3+pre-research, Self development of BEV End-to-end Perception Autonomous Driving Closed door Seminar. The 6th Automotive Technology Review held by the China Society of Automotive Engineers - \u201cThe Potential and Paths of Applying AI Large Models to Autonomous Driving\u201d closed seminar was held on July 11, 2023 (Tuesday) from 14:00-17:30 pm Held in the Paris Hall on the third floor of Pullman Hotel Xingji, Yizhuang Economic Development Zone, Beijing.</li> <li> 05/2023: L3+pre-research, Completed Self construction of a scalable container platform for deep learning algorithm development and training environment, Dongfeng Technology Center computer room, Wuhan.</li> <li> 03/2023: L3+pre-research, Development of visual multi-task perception system PMP based on surround fisheye view,include IPM Visual Parking slot detection system development using fisheye camera, with  Calmcar , Wuhan.</li> <li> 11/2022: L3+pre-research, Kick-off meeting of BEV Multi-tasking visual perception system \u201cSMP\u201ddevelopment with Wuhan University , Wuhan.</li> <li> 08/2022: L3-project, IPM view v-SLAM system completed, Wuhan.</li> <li> 07/2022: L3-project, G59 vehicle platform L3- HighwayAssist function completed, Wuhan.</li> <li> 10/2021: L3+pre-research, Self development of visual multi-task perception system \u201cPMP\u201d based on surround fisheye view, Wuhan.</li> <li> 09/2021: At the 6th Science and Technology Innovation Week, the memory parking function based on theIPM view v-SLAM system was demonstrated to the public in the parking lot of Building #2 of the Technology Center. The maximum distance of memory parking is 500 meters, at 2021 Dongfeng Motor Brand Autumn Press Conference and the 6th Science and Technology Innovation Week.</li> <li> 09/2021: L3-project, HighwayAssist driving system development scientific research project completed, The scientific research technology has entered the engineering stage and plans to equip the G59 vehicle platform with L3- HighwayAssist function, Wuhan.</li> <li> 01/2021: L3+pre-research, Obstacle detection using Hesai 64-line lidar based on Xavier platform, with Mingshan Jiang(Changan Automobile Software Technology), Zhigao He(Lianyou Technology). Wuhan.</li> <li> 10/2020: L3-project, IPM view v-SLAM system development in cooperation with  Calmcar, and the target platform is TDA4 TI, Tianjin and Wuhan.</li> <li> 10/2020: L3+pre-research, Kick-off meeting of the L3+ autonomous driving perception pre-research project based on DDS communication, with interns Ruichen Tan (Ohio University), Hao Chao, Zhigao He,Peijie Chen, etc. Four major categories of things were accomplished: 1. Established a communication matrix and completed the hierarchical decomposition of software modules. 2. L3+ implements CAN DBC parsing and successfully integrates the L3- fused simulink model (c code generated using a code generation tool). 3. Completed the obstacle detection of visual YOLO and lidar YOLO 4. Draw the laser SLAM-NDT to obtain the point cloud map of the Dongfeng technology center, and use RoadRunner to draw the map to obtain the road network OpenDrive map. Fusion loaction through IMU+GPS. </li> <li> 08/2020: L3-project, Offline two-stage object detection perception model, perform perceptual fusion ACC recall test, developed with Mengqi Lu(Lianyou Technology), Wuhan.</li> <li> 06/2020: L3-project, Kick-off meeting of v-SLAM system development project was launched, for LAPA memory parking. SLAM (Simultaneous Localization and Mapping) is one of the key technologies of LAPA memory parking; when the vehicle is in a ground or underground parking garage and there is no reliable GPS signal coverage, LAPA (memory parking) needs to use SLAM technology for vehicle positioning, Wuhan.</li> <li> 01/2020: L3-project, Kick-off meeting of HighwayAssist driving system development scientific research project, based on smart cameras and millimeter wave radar, I was mainly responsible for developing the lane line module and the development tools are simulink and code generation tools, based on AutoSar middleware, Wuhan, January 10th, PM8:00-23:00.</li> </ul> <p> </p> \ud83d\udcddSelected Publications  Pictures Comments Visual SLAM in Long-Range Autonomous Parking Application Based on Instance-Aware Semantic Segmentation via Multi-Task Network Cascades and Metric Learning Scheme Yixiong Yan, Yang Hang, Tianren Hu, Hao Yu, and Feng Lai <p> </p> \ud83d\udcdd Preprints Pictures Comments Streaming Object Detection on Fisheye Cameras for Automatic ParkingYixiong Yan* <p> </p> \ud83d\udcda Academic Activities <p>Conference Reviewers &amp; Journal Reviewers</p> <ul> <li> SAE Technical Papers 2021</li> </ul> <p>Tech. Talks</p> <ul> <li> \u201cThe Potential and Path of AI Big Models Applied to Autonomous Driving\u201d Closed door Seminar, The 6th Automotive Technology Review, China-SAE, July 11, 2023</li> <li> Dongfeng Motor and Huazhong University of Science and Technology: Closed-door meeting on autonomous driving and visual perception, Participating vlrlab team, etc. May 24, 2022.</li> <li> 2021 SAE WCX World Congress Digital Summit between April 13-15, 2021</li> </ul> <p> </p> \ud83c\udf93 Education Pictures Comments B.E. degree from School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, ChinaSep. 2015 - July 2019 M.A. degree from School of Politics and Public Administration, Wuhan University, Wuhan, ChinaSep. 2023 - July 2025 <p> </p> \ud83e\uddd1\ud83d\udcbb Internship and Cooperation Pictures Comments Cooperate with School of Computer of science, Wuhan University to develop visual perception algorithm technology, and serve as project manager(PM)Jan. 2023 - Sept. 2023 Cooperated with Calmcar to develop an automatic parking visual location algorithm, served as the project leader(PL) and accomplished the development work, and successfully promoted the mass production application of the automatic parking function.Jan. 2021 - July. 2022 Cooperated with Jilin University to develop a perception and fusion algorithm, served as lane detection technology manager(TM), and successfully converted the scientific research code to the application of mass production vehicleJan. 2020 - July. 2022 Joined Dongfeng Motor Group Co., Ltd. Technology Center, Intelligent Connected Department, Perception Fusion Department, and served as algorithm engineer(AE)Aug. 2019 - Now Under the guidance of Professor Xifan Yao of School of Mechanical and Automotive Engineering, South China University of Technology, I completed the research and exploration of simultaneous localization and mapping (SLAM) based on lidar. In the evaluation system of the college, my graduation thesis achieved excellent results. During this experience, I learned scientific research methodology and correct scientific research ethics and completed scientific research work through data retrieval, document translation, method refinement, and experimental verification.Sept. 2018 - Jun. 2019 \ue6c2Worked as an application engineering intern at Texas Instruments, passed the primary operation qualification of the laboratory, and learned the technical knowledge of analog electronics. As a member of the mass market team, responsible for new solutions and troubleshooting services for CAN communication and motor drive chips, responsible for 10-20 downstream customers, and received high praise from customers for communication skills and professional quality.July 2018 - Sep. 2018 Served as the leader of the electronic control group (with about 10 members) of the Formula Racing Laboratory of the South China University of Technology, won the first prize in the 2017 Formula Student China(FSC). Responsible for development plans, teamwork arrangements, and progress advancement. Improved the circuit of the whole vehicle, completed the hardware design and software writing of the new generation of engine starting circuit board, the main control board, and the steering wheel remote control circuit board, completed the CATIA modeling of the circuit and the fixed scheme design, and improved the variable tail wing circuit system of the car design. Promoted the construction of the team\u2019s ability system and normative standards.July. 2016 - July 2018 <p> </p> \ud83c\udf96 Awards <ul> <li> The 7th Dongfeng Youth Independent Innovation Technology Award for \u201cDevelopment and Application of Visual Parking Slots Perception for Automatic Parking\u201d, 2023, Dongfeng Motor Corp.</li> <li> Gold Award for L2 assisted driving lane keeping function at 80km/h turning based on Dongfeng Fengshen Haoji SUV passenger car,Tianjin,2022, World Intelligent Driving Challenge (WIDC).</li> <li> Excellence Award for \u201cL2 Perception Fusion Development Tool System\u201d, 2020, Dongfeng Motor Corp.</li> <li> Outstanding Student Officer, Outstanding Student, National Inspirational Scholarship, Esquel Group Enterprise Scholarship, 2015-2019</li> </ul> <p> </p> \ud83d\udee0 Open Source Projects Pictures Comments Real-time Object Detection on Fisheye Cameras for Streaming Perceptionrepo:Gitee Curl Software-Over-the-Air-based-on-Webdav repo:Gitee Curl Process Management System based on php-nginx-mysqlrepo:Gitee Curl <p> </p> \ud83d\udcbb Demos <p> </p> \ud83d\udcdd  Interests And Hobbie <p> </p> <p>Guest Statistics <p> </p></p>"},{"location":"Academic/Academic/","title":"Academic","text":""},{"location":"Academic/Academic/#conference-reviewers","title":"Conference Reviewers","text":"<ul> <li>\u2022 Neural Information Processing Systems (NeurIPS), 2022/2023</li> <li>\u2022 International Conference on Machine Learning (ICML), 2022/2023</li> <li>\u2022 AAAI Conference on Artificial Intelligence (AAAI), 2022/2023</li> <li>\u2022 ACM International Conference on Multimedia (ACM MM), 2021/2022</li> <li>\u2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021/2022/2023</li> <li>\u2022 IEEE/CVF International Conference on Computer Vision (ICCV), 2023</li> <li>\u2022 European Conference on Computer Vision (ECCV), 2022</li> </ul>"},{"location":"Academic/Academic/#journal-reviewers","title":"Journal Reviewers","text":"<ul> <li>\u2022 IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li> <li>\u2022 International Journal of Computer Vision (IJCV)</li> <li>\u2022 IEEE Transactions on Image Processing (TIP)</li> <li>\u2022 Pattern Recognition (PR)</li> <li>\u2022 IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li> <li>\u2022 IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li> <li>\u2022 IEEE Geoscience and Remote Sensing Letters (GRSL)</li> <li>\u2022 IEEE Transactions on Intelligent Transportation Systems (TITS)</li> <li>\u2022 IEEE Transactions on Multimedia Computing Communications and Applications (TOMM)</li> <li>\u2022 Remote Sensing</li> </ul>"},{"location":"Academic/Academic/#tech-talks","title":"Tech. Talks","text":"<ul> <li>\u2022 03 / 2023:  OpenMMLab [OpenMMLab\u793e\u533a\u5f00\u653e\u9ea6], [slides], [bilibili playback], [zhihu playback]</li> <li>\u2022 12 / 2022:  Doctoral Forum of PRCV 2022 [PRCV 2022 \u535a\u58eb\u751f\u8bba\u575b]</li> <li>\u2022 07 / 2022:  OpenMMLab [OpenMMLab\u793e\u533a\u5f00\u653e\u9ea6], [slides], [bilibili playback], [zhihu playback]</li> <li>\u2022 06 / 2022:  Young Scholars Forum of Wu Wenjun\u2019s artificial intelligence doctoral class [\u5434\u73edTalk], [slides]</li> <li>\u2022 12 / 2021:  The fifth Jittor Forum [\u7b2c\u4e94\u671f\u201c\u8ba1\u56fe\u201d\u8bba\u575b], [slides]</li> <li>\u2022 05 / 2021:  Magnolia Young Scholar Forum [\u767d\u7389\u5170\u9752\u5e74\u5b66\u8005\u8bba\u575b], [slides]</li> </ul>"},{"location":"News/News/","title":"News","text":"<p><pre><code>    gantt\n    dateFormat  YYYY-MM-DD\n    title Adding GANTT diagram functionality to mermaid\n\n    section A section\n    Completed task            :done,    des1, 2014-01-06,2014-01-08\n    Active task               :active,  des2, 2014-01-09, 3d\n    Future task               :         des3, after des2, 5d\n    Future task2              :         des4, after des3, 5d\n\n    section Critical tasks\n    Completed task in the critical line :crit, done, 2014-01-06,24h\n    Implement parser and jison          :crit, done, after des1, 2d\n    Create tests for parser             :crit, active, 3d\n    Future task in critical line        :crit, 5d\n    Create tests for renderer           :2d\n    Add to mermaid                      :1d\n\n    section Documentation\n    Describe gantt syntax               :active, a1, after des1, 3d\n    Add gantt diagram to demo page      :after a1  , 20h\n    Add another diagram to demo page    :doc1, after a1  , 48h\n\n    section Last section\n    Describe gantt syntax               :after doc1, 3d\n    Add gantt diagram to demo page      :20h\n    Add another diagram to demo page    :48h</code></pre> <pre><code>graph LR\nA[Square Rect] -- Link text --&gt; B((Circle))\nA --&gt; C(Round Rect)\nB --&gt; D{Rhombus}\nC --&gt; D</code></pre></p> <pre><code>graph TB\nsq[Square shape] --&gt; ci((Circle shape))\n\nsubgraph A subgraph\n    od&gt;Odd shape]-- Two line&lt;br&gt;edge comment --&gt; ro\n    di{Diamond with &lt;br/&gt; line break} -.-&gt; ro(Rounded&lt;br&gt;square&lt;br&gt;shape)\n    di==&gt;ro2(Rounded square shape)\nend\n\n%% Notice that no text in shape are added here instead that is appended further down\ne --&gt; od3&gt;Really long text with linebreak&lt;br&gt;in an Odd shape]\n\n%% Comments after double percent signs\ne((Inner / circle&lt;br&gt;and some odd &lt;br&gt;special characters)) --&gt; f(,.?!+-*\u0632)\n\ncyr[Cyrillic]--&gt;cyr2((Circle shape \u041d\u0430\u0447\u0430\u043b\u043e));\n\n classDef green fill:#9f6,stroke:#333,stroke-width:2px;\n classDef orange fill:#f96,stroke:#333,stroke-width:4px;\n class sq,e green\n class di orange</code></pre> <pre><code>sequenceDiagram\nAlice -&gt;&gt; Bob: Hello Bob, how are you?\nBob--&gt;&gt;John: How about you John?\nBob--x Alice: I am good thanks!\nBob-x John: I am good thanks!\nNote right of John: Bob thinks a long&lt;br/&gt;long time, so long&lt;br/&gt;that the text does&lt;br/&gt;not fit on a row.\n\nBob--&gt;Alice: Checking with John...\nAlice-&gt;John: Yes... John, how are you?</code></pre> <pre><code>sequenceDiagram\nloop Daily query\n    Alice-&gt;&gt;Bob: Hello Bob, how are you?\n    alt is sick\n        Bob-&gt;&gt;Alice: Not so good :(\n    else is well\n        Bob-&gt;&gt;Alice: Feeling fresh like a daisy\n    end\n\n    opt Extra response\n        Bob-&gt;&gt;Alice: Thanks for asking\n    end\nend</code></pre> <p>aa</p> <pre><code>gantt\ndateFormat  YYYY-MM-DD\ntitle Adding GANTT diagram functionality to mermaid\n\nsection A section\nCompleted task:done,    des1, 2014-01-06,2014-01-08\nActive task:active,  des2, 2014-01-09, 3d\n</code></pre> <pre><code>gantt\ndateFormat  YYYY-MM-DD\ntitle Adding GANTT diagram functionality to mermaid\n\nsection A section\nCompleted task            :done,    des1, 2014-01-06,2014-01-08\nActive task               :active,  des2, 2014-01-09, 3d\nFuture task               :         des3, after des2, 5d\nFuture task2              :         des4, after des3, 5d\n\nsection Critical tasks\nCompleted task in the critical line :crit, done, 2014-01-06,24h\nImplement parser and jison          :crit, done, after des1, 2d\nCreate tests for parser             :crit, active, 3d\nFuture task in critical line        :crit, 5d\nCreate tests for renderer           :2d\nAdd to mermaid                      :1d\n\nsection Documentation\nDescribe gantt syntax               :active, a1, after des1, 3d\nAdd gantt diagram to demo page      :after a1  , 20h\nAdd another diagram to demo page    :doc1, after a1  , 48h\n\nsection Last section\nDescribe gantt syntax               :after doc1, 3d\nAdd gantt diagram to demo page      :20h\nAdd another diagram to demo page    :48h</code></pre> <pre><code>st=&gt;start: Start:&gt;http://www.google.com[blank]\ne=&gt;end:&gt;http://www.google.com\nop1=&gt;operation: My Operation\nsub1=&gt;subroutine: My Subroutine\ncond=&gt;condition: Yes\nor No?:&gt;http://www.google.com\nio=&gt;inputoutput: catch something...\nst-&gt;op1-&gt;cond\ncond(yes)-&gt;io-&gt;e\ncond(no)-&gt;sub1(right)-&gt;op1</code></pre> <pre><code>Title: Here is a title\nA-&gt;B: Normal line\nB--&gt;C: Dashed line\nC-&gt;&gt;D: Open arrow\nD--&gt;&gt;A: Dashed open arrow</code></pre> <pre><code>graph TD\n    B[\"fa:fa-twitter for peace\"]\n    B--&gt;C[fa:fa-ban forbidden]\n    B--&gt;D(fa:fa-spinner);\n    B--&gt;E(A fa:fa-camera-retro perhaps?);\n</code></pre> <p><pre><code>    gantt\n    dateFormat  YYYY-MM-DD\n    title Adding GANTT diagram functionality to mermaid\n\n    section A section\n    Completed task            :done,    des1, 2014-01-06,2014-01-08\n    Active task               :active,  des2, 2014-01-09, 3d\n    Future task               :         des3, after des2, 5d\n    Future task2              :         des4, after des3, 5d\n\n    section Critical tasks\n    Completed task in the critical line :crit, done, 2014-01-06,24h\n    Implement parser and jison          :crit, done, after des1, 2d\n    Create tests for parser             :crit, active, 3d\n    Future task in critical line        :crit, 5d\n    Create tests for renderer           :2d\n    Add to mermaid                      :1d\n\n    section Documentation\n    Describe gantt syntax               :active, a1, after des1, 3d\n    Add gantt diagram to demo page      :after a1  , 20h\n    Add another diagram to demo page    :doc1, after a1  , 48h\n\n    section Last section\n    Describe gantt syntax               :after doc1, 3d\n    Add gantt diagram to demo page      :20h\n    Add another diagram to demo page    :48h</code></pre> <pre><code>graph LR\nA[Square Rect] -- Link text --&gt; B((Circle))\nA --&gt; C(Round Rect)\nB --&gt; D{Rhombus}\nC --&gt; D</code></pre></p> <pre><code>graph TB\nsq[Square shape] --&gt; ci((Circle shape))\n\nsubgraph A subgraph\n    od&gt;Odd shape]-- Two line&lt;br&gt;edge comment --&gt; ro\n    di{Diamond with &lt;br/&gt; line break} -.-&gt; ro(Rounded&lt;br&gt;square&lt;br&gt;shape)\n    di==&gt;ro2(Rounded square shape)\nend\n\n%% Notice that no text in shape are added here instead that is appended further down\ne --&gt; od3&gt;Really long text with linebreak&lt;br&gt;in an Odd shape]\n\n%% Comments after double percent signs\ne((Inner / circle&lt;br&gt;and some odd &lt;br&gt;special characters)) --&gt; f(,.?!+-*\u0632)\n\ncyr[Cyrillic]--&gt;cyr2((Circle shape \u041d\u0430\u0447\u0430\u043b\u043e));\n\n classDef green fill:#9f6,stroke:#333,stroke-width:2px;\n classDef orange fill:#f96,stroke:#333,stroke-width:4px;\n class sq,e green\n class di orange</code></pre> <pre><code>sequenceDiagram\nAlice -&gt;&gt; Bob: Hello Bob, how are you?\nBob--&gt;&gt;John: How about you John?\nBob--x Alice: I am good thanks!\nBob-x John: I am good thanks!\nNote right of John: Bob thinks a long&lt;br/&gt;long time, so long&lt;br/&gt;that the text does&lt;br/&gt;not fit on a row.\n\nBob--&gt;Alice: Checking with John...\nAlice-&gt;John: Yes... John, how are you?</code></pre> <pre><code>sequenceDiagram\nloop Daily query\n    Alice-&gt;&gt;Bob: Hello Bob, how are you?\n    alt is sick\n        Bob-&gt;&gt;Alice: Not so good :(\n    else is well\n        Bob-&gt;&gt;Alice: Feeling fresh like a daisy\n    end\n\n    opt Extra response\n        Bob-&gt;&gt;Alice: Thanks for asking\n    end\nend</code></pre> <p>aa</p> <pre><code>gantt\ndateFormat  YYYY-MM-DD\ntitle Adding GANTT diagram functionality to mermaid\n\nsection A section\nCompleted task:done,    des1, 2014-01-06,2014-01-08\nActive task:active,  des2, 2014-01-09, 3d\n</code></pre> <pre><code>gantt\ndateFormat  YYYY-MM-DD\ntitle Adding GANTT diagram functionality to mermaid\n\nsection A section\nCompleted task            :done,    des1, 2014-01-06,2014-01-08\nActive task               :active,  des2, 2014-01-09, 3d\nFuture task               :         des3, after des2, 5d\nFuture task2              :         des4, after des3, 5d\n\nsection Critical tasks\nCompleted task in the critical line :crit, done, 2014-01-06,24h\nImplement parser and jison          :crit, done, after des1, 2d\nCreate tests for parser             :crit, active, 3d\nFuture task in critical line        :crit, 5d\nCreate tests for renderer           :2d\nAdd to mermaid                      :1d\n\nsection Documentation\nDescribe gantt syntax               :active, a1, after des1, 3d\nAdd gantt diagram to demo page      :after a1  , 20h\nAdd another diagram to demo page    :doc1, after a1  , 48h\n\nsection Last section\nDescribe gantt syntax               :after doc1, 3d\nAdd gantt diagram to demo page      :20h\nAdd another diagram to demo page    :48h</code></pre> <pre><code>st=&gt;start: Start:&gt;http://www.google.com[blank]\ne=&gt;end:&gt;http://www.google.com\nop1=&gt;operation: My Operation\nsub1=&gt;subroutine: My Subroutine\ncond=&gt;condition: Yes\nor No?:&gt;http://www.google.com\nio=&gt;inputoutput: catch something...\nst-&gt;op1-&gt;cond\ncond(yes)-&gt;io-&gt;e\ncond(no)-&gt;sub1(right)-&gt;op1</code></pre> <pre><code>Title: Here is a title\nA-&gt;B: Normal line\nB--&gt;C: Dashed line\nC-&gt;&gt;D: Open arrow\nD--&gt;&gt;A: Dashed open arrow</code></pre> <pre><code>graph TD\n    B[\"fa:fa-twitter for peace\"]\n    B--&gt;C[fa:fa-ban forbidden]\n    B--&gt;D(fa:fa-spinner);\n    B--&gt;E(A fa:fa-camera-retro perhaps?);\n</code></pre>"},{"location":"Projects/Projects/","title":"Projects","text":"<p> HomePage <p></p> Yixiong Yan (\u4e25\u4e49\u96c4) Algorithm Engineer at Perception and Fusion Team Department of Intelligent Driving Software Development, Intelligent Software Center Dongfeng Motor Group Co., Ltd. Technical Center, Wuhan, China, 430056 Master. Student at Wuhan University, Wuhan, China Bachelor. Student at South China University of Technology, Guangzhou, China Email: meeason@foxmail.com <p></p>"},{"location":"Projects/Projects/#biography","title":"Biography","text":"<p>Yixiong Yan is now an Perception Algorithm Engineer in Department of Intelligent Driving Software Development,  Dongfeng Motor Group Co., Ltd. Technical Center starting from Autumn 2019, Wuhan, China. His research and development advisor is Hang Yang(2020-2021), Xinjuan Tuo(2022-2023).</p> <p>Yixiong Yan received the B. E. degree from School of Machinery and Automobile Engineering,  South China University of Technology, Guangzhou, China, in 2019. He will receive the M. A. degree from School of Politics and Public Administration, Wuhan University, Wuhan, China, in 2025.</p> <p>Yixiong Yan\u2019s research interests include visual perception and visual location  in the field of autonomous driving, with a focus on generic/oriented/3D object detection, lane detection and SLAM. He has published some papers at the international conferences and journals and published some key patents. He is the leading contributor to the BEV perception(2022-2024) and IPM SLAM(2020-2021) scientific research projects, and lane detection module application (2020-2021)  in mass-produced vehicles based on Mobileye in Dongfeng Motor Group Co., Ltd..</p> <p>The autonomous driving software department at Dongfeng Motor Group Co., Ltd. is now hiring. If you are interested in internship/researcher positions related to autonomous driving perception in the filed of lidar or camera, please feel free to contact me through the email. </p>"},{"location":"Projects/Projects/#news","title":"\ud83d\udd25 News","text":"<ul> <li> 03/2022: </li> <li> 03/2021: </li> <li> 03/2020: </li> <li> 03/2019: </li> </ul>"},{"location":"Projects/Projects/#recent-works","title":"\ud83d\udcddRecent Works","text":"Pictures Comments Visual SLAM in Long-Range Autonomous Parking Application Based on Instance-Aware Semantic Segmentation via Multi-Task Network Cascades and Metric Learning Scheme Yixiong Yan, Yang Hang, Tianren Hu, Hao Yu, and Feng Lai"},{"location":"Projects/Projects/#preprints","title":"\ud83d\udcdd Preprints","text":"Pictures Comments Rotate Object Detection on Fisheye Cameras for Streaming PerceptionYixiong Yan*"},{"location":"Projects/Projects/#academic-activities","title":"\ud83d\udcda Academic Activities","text":"<p>Conference Reviewers</p> <ul> <li> SAE Technical Papers 2021</li> </ul> <p>Journal Reviewers</p> <ul> <li> Null: </li> </ul> <p>Tech. Talks</p> <ul> <li> 2021 SAE WCX World Congress Digital Summit between April 13-15, 2021</li> </ul>"},{"location":"Projects/Projects/#education","title":"\ud83c\udf93 Education","text":"Pictures Comments B.E. degree from School of Machinery and Automobile Engineering, South China University of Technology, Guangzhou, ChinaSep. 2015 - July 2019 M.A. degree from School of Electronic, School of Politics and Public Administration, Wuhan University, Wuhan, ChinaSep. 2023 - July 2025"},{"location":"Projects/Projects/#internship-and-cooperation","title":"\ud83e\uddd1\ud83d\udcbb Internship and Cooperation","text":"Pictures Comments Cooperate with Wuhan University to develop visual perception algorithm technology, and serve as project manager(PM)Janu. 2023 - Now Cooperated with Calmcar to develop an automatic parking visual location algorithm, served as the project leader(PL) and accomplished the development work, and successfully promoted the mass production application of the automatic parking function.Janu. 2021 - July. 2022 Cooperated with Jilin University to develop a perception and fusion algorithm, served as lane detection technology manager(TM), and successfully converted the scientific research code to the application of mass production vehicleJanu. 2020 - July. 2022 Joined Dongfeng Motor Group Co., Ltd. Technology Center, Intelligent Connected Department, Perception Fusion Department, and served as algorithm engineer(AE)Aug. 2019 - Now Under the guidance of Professor Xifan Yao of the South China University of Technology, I completed the research and exploration of simultaneous localization and mapping (SLAM) based on lidar. In the evaluation system of the college, my graduation thesis achieved excellent results. During this experience, I learned scientific research methodology and correct scientific research ethics and completed scientific research work through data retrieval, document translation, method refinement, and experimental verification.Aug. 2019 - Now Worked as an application engineering intern at Texas Instruments, passed the primary operation qualification of the laboratory, and learned the technical knowledge of analog electronics. As a member of the mass market team, responsible for new solutions and troubleshooting services for CAN communication and motor drive chips, responsible for 10-20 downstream customers, and received high praise from customers for communication skills and professional quality.July 2018 - Sep. 2018 Served as the leader of the electronic control group (with about 10 members) of the Formula Racing Laboratory of the South China University of Technology, won the first prize in the 2017 Formula Student China(FSC). Responsible for development plans, teamwork arrangements, and progress advancement. Improved the circuit of the whole vehicle, completed the hardware design and software writing of the new generation of engine starting circuit board, the main control board, and the steering wheel remote control circuit board, completed the CATIA modeling of the circuit and the fixed scheme design, and improved the variable tail wing circuit system of the car design. Promoted the construction of the team\u2019s ability system and normative standards.July. 2016 - July 2018"},{"location":"Projects/Projects/#awards","title":"\ud83c\udf96 Awards","text":"<ul> <li> Excellence Award for L2 Perception Fusion Development Tool System, 2020, Dongfeng Motor Co.</li> <li> Outstanding Student Officer, Outstanding Student, National Inspirational Scholarship, Esquel Group Enterprise Scholarship, 2015-2019</li> </ul>"},{"location":"Projects/Projects/#projects","title":"\ud83d\udee0 Projects","text":"<ul> <li> Gitee:Real-time Object Detection on Fisheye Cameras for Streaming Perception</li> </ul>"},{"location":"Projects/Projects/#demos","title":"\ud83d\udcbb Demos","text":"<p>Guest Statistics <p> </p></p>"},{"location":"Videos/Videos/","title":"\u4fe1\u606f\u7edf\u8ba1","text":""},{"location":"Videos/Videos/#5","title":"\u63d0\u524d5\u5206\u949f\u5f00\u59cb\u6696\u573a","text":""},{"location":"Videos/Videos/#1","title":"1.\u786e\u5b9a\u4f1a\u8bae\u7c7b\u578b","text":"<ul> <li> \u5206\u4eab\u4f1a\uff1b</li> <li> \u51b3\u7b56\u4f1a\u8bae\u3002</li> </ul>"},{"location":"Videos/Videos/#2","title":"2.\u4f1a\u8bae\u5230\u4f1a\u7edf\u8ba1\u3001\u4f1a\u8bae\u5f55\u97f3","text":""},{"location":"Videos/Videos/#3","title":"3.\u4e94\u6709","text":"<ul> <li> \u6709\u51c6\u5907</li> <li> \u6709\u4e3b\u9898</li> <li> \u6709\u7eaa\u5f8b</li> <li> \u6709\u7a0b\u5e8f</li> <li> \u6709\u68c0\u67e5</li> </ul>"},{"location":"Videos/Videos/#4","title":"4.\u4e94\u4e0d","text":"<ul> <li> \u4e0d\u52a1\u865a</li> <li> \u4e0d\u8ba8\u8bba\u7ec6\u8282</li> <li> \u4e0d\u62b1\u6028\u8bc9\u82e6</li> <li> \u4e0d\u641e\u4e00\u8a00\u5802</li> <li> \u4e0d\u8dd1\u9898</li> </ul>"},{"location":"Videos/Videos/#5_1","title":"5.\u5f00\u4f1a\u987a\u5e8f\u548c\u5185\u5bb9\u7684\u6846\u67b6","text":"<ul> <li> \u597d\u7684\u65b9\u9762</li> <li> \u5b58\u5728\u7684\u95ee\u9898</li> <li> \u63d0\u51fa\u6539\u8fdb\u63aa\u65bd</li> <li> \u5e03\u7f6e\u4e0b\u4e00\u5e03\u5de5\u4f5c</li> </ul>"},{"location":"Videos/Videos/#6","title":"6.\u5f3a\u8c03\u7406\u89e3\u4f1a\u8bae\u5185\u5bb9","text":"<ul> <li> \u786e\u4fdd\u53c2\u4f1a\u8005\u4fe1\u606f\u5bf9\u79f0</li> </ul>"},{"location":"Videos/Videos/#7","title":"7.\u5728\u7ebf\u6536\u96c6\u6539\u5584\u5efa\u8bae","text":""},{"location":"Videos/Videos/#8","title":"8.\u4f8b\u4f1a\u5185\u5bb9\u516c\u5e03","text":""},{"location":"Videos/Videos/#9","title":"9.\u9879\u76ee\u9700\u6c42","text":"<p>\uff08\u63d0\u51fa\u9700\u6c42\u53ef\u80fd\u4e0d\u80fd\u53ca\u65f6\u54cd\u5e94\uff09 - \u7b2c\u4e00\u65f6\u95f4\u54cd\u5e94\u5185\u5bb9 - \u540e\u7eed\u76f8\u5e94\u5185\u5bb9\u6982\u8ff0</p>"},{"location":"Videos/Videos/#10","title":"10.\u4fdd\u5bc6\u7ea7\u522b","text":"<p>\u5173\u952e\u8bcd\uff1a\u4e0d\u8ba8\u8bba\u7ec6\u8282\u3001\u51c6\u5907\u3001\u4e0d\u8dd1\u9898\u3001\u5de5\u4f5c\u5e03\u7f6e\u3001\u5f3a\u8c03\u7406\u89e3</p> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Nulla lobortis egestas semper</li> <li> Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Sed egestas felis quis elit dapibus, ac aliquet turpis mattis</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> <li> Nulla vel eros venenatis, imperdiet enim id, faucibus nisi</li> </ul> <p></p>"},{"location":"other/vi/","title":"Vi","text":""},{"location":"other/wechat/","title":"Wechat","text":""}]}